{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc0963f",
   "metadata": {},
   "source": [
    "# 2023 Fall AI605 Assignment 2: Attention and Transformers\n",
    "\n",
    "## Rubric\n",
    "\n",
    "### Deadline\n",
    "\n",
    "The deadline for this assignment is: Friday 20th October 2023 (Week 8) 11:59pm\n",
    "\n",
    "### Submission\n",
    "\n",
    "Please submit your assignment via [KLMS](https://klms.kaist.ac.kr). You must submit the Jupyter Notebook file (.ipynb) with all code and model outputs. **For Problem 3.4, you must submit the training curve (loss against traning step) with your notebook**\n",
    "\n",
    "Use in-line LaTeX for mathematical expressions.\n",
    "\n",
    "### Collaboration\n",
    "\n",
    "This assignment is an individual assingnment. It is **not** a group assignment so make sure your answer and code are your own.\n",
    "\n",
    "### Grading\n",
    "\n",
    "The total number of marks avaiable is 25 points.\n",
    "\n",
    "### Environment\n",
    "\n",
    "The use of a GPU is recommended for problem 3. For Problem 3.4, limit computation time to approximately 2 hours with a GPU. The suggested environment for this is Python 3.9. Run the following cell to set up the environment.\n",
    "\n",
    "### Data\n",
    "\n",
    "Problem 3.4 will make use of the English portion of the C4 dataset. We have prepared a sample of 10,000,000 sentences for training.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "The following libraries should be used for the project. You should not need any other libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc53cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch tqdm datasets transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b63e1",
   "metadata": {},
   "source": [
    "# Problem 1 - Attention (10 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17ec8f",
   "metadata": {},
   "source": [
    "Recall that attention can be viewed as a weighted sum of vectors:\n",
    "\n",
    "$$\\mathbf{z} = \\sum_{c=1}^n \\alpha_i \\mathbf{h}_i$$\n",
    "\n",
    "Where, in dot product attention, the weights $\\alpha = \\{\\alpha_1,\\ldots,\\alpha_n \\}$ are determined as softmax over the inner product of the vector $\\mathbf{h}_i \\in \\{\\mathbf{h}_1,\\ldots, \\mathbf{h}_n\\}$ and some query $\\mathbf{q}$ where $\\mathbf{q} \\in \\mathbb{R}^d$ and $\\mathbf{h}_i\\in\\mathbb{R}^d$.\n",
    "\n",
    "$$\\alpha_i = \\frac{\\exp \\mathbf{h}_i^T \\mathbf{q}}{\\sum_{j=1}^n \\exp \\mathbf{h}_j^T \\mathbf{q}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd16dc1",
   "metadata": {},
   "source": [
    "**Problem 1.1** (2 point) State the bounds of each element in $\\alpha$ (1 point). Is it a well-formed categorical probability distribution? **Explain why** (1 point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e71e641",
   "metadata": {},
   "source": [
    "Given the definition of softmax, let us first state the bounds of each element in $\\alpha$.\n",
    "\n",
    "For each $\\alpha_i$:\n",
    "\n",
    "1. The numerator is $\\exp \\mathbf{h}_i^\\top \\mathbf{q}$, which is always non-negative (since the exponential function always produces a non-negative value).\n",
    "2. The denominator is the sum of all such non-negative values. Therefore, the denominator is also always positive and at least as large as the numerator.\n",
    "\n",
    "Thus, for each $i$: $0 \\leq \\alpha_i \\leq 1$.\n",
    "\n",
    "This shows the bounds of each element in $\\alpha$.\n",
    "\n",
    "Now, to determine if it is a well-formed categorical probability distribution:\n",
    "\n",
    "1. As mentioned before, each $\\alpha_i$ is bounded by $[0, 1]$.\n",
    "2. The sum of all $\\alpha_i$'s is $1$. This is inherent to the softmax operation.\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n \\alpha_i = \\sum_{i=1}^n \\frac{\\exp \\mathbf{h}_i^\\top \\mathbf{q}}{\\sum_{j=1}^n \\exp \\mathbf{h}_j^\\top \\mathbf{q}} = \\frac{\\sum_{i=1}^n \\exp \\mathbf{h}_i^\\top \\mathbf{q}}{\\sum_{j=1}^n \\exp \\mathbf{h}_j^\\top \\mathbf{q}} = 1\n",
    "$$\n",
    "\n",
    "Given these two properties, we can conclude that $\\alpha$ is a well-formed categorical probability distribution. The elements of $\\alpha$ are non-negative, they sum to 1, and each element represents the probability of the corresponding $\\mathbf{h}_i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b00431",
   "metadata": {},
   "source": [
    "For each $\\alpha_i$:\n",
    "\n",
    "1. The numerator is $\\exp \\mathbf{h}_i^\\top \\mathbf{q}$, which is always non-negative (since the exponential function always produces a non-negative value).\n",
    "2. The denominator is the sum of all such non-negative values. Therefore, the denominator is also always positive and at least as large as the numerator.\n",
    "\n",
    "Thus, for each $i$: $0 \\leq \\alpha_i \\leq 1$.\n",
    "\n",
    "This shows the bounds of each element in $\\alpha$.\n",
    "\n",
    "Now, to determine if it's a well-formed categorical probability distribution:\n",
    "\n",
    "1. As mentioned before, each $\\alpha_i$ is bounded by [0, 1].\n",
    "2. The sum of all $\\alpha_i$'s is 1. This is inherent to the softmax operation.\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n \\alpha_i = \\sum_{i=1}^n \\frac{\\exp \\mathbf{h}_i^\\top \\mathbf{q}}{\\sum_{j=1}^n \\exp \\mathbf{h}_j^\\top \\mathbf{q}} = \\frac{\\sum_{i=1}^n \\exp \\mathbf{h}_i^\\top \\mathbf{q}}{\\sum_{j=1}^n \\exp \\mathbf{h}_j^\\top \\mathbf{q}} = 1\n",
    "$$\n",
    "\n",
    "Given these two properties, we can conclude that $\\alpha$ is a well-formed categorical probability distribution. The elements of $\\alpha$ are non-negative, they sum to 1, and each element represents the probability of the corresponding $\\mathbf{h}_i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80297f55",
   "metadata": {},
   "source": [
    "**Problem 1.2** (2 point) Compare the attention mechanisms of Dot Product attention, Bahdanau (concatenate) attention and Luong (linear) attention from the lecture in Week 5. Assuming a hidden dimension size of $d$ dimensions, compare how many additional parameters these attention mechanisms introduce.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b7d720",
   "metadata": {},
   "source": [
    "- **Dot product attention**\n",
    "\n",
    "  $$\n",
    "  \\text{score}(\\mathbf{u}, \\mathbf{v}) = \\mathbf{u} \\cdot \\mathbf{v}\n",
    "  $$\n",
    "\n",
    "  Introduces zero learnable parameters.\n",
    "\n",
    "- **Bahdanau attention**\n",
    "\n",
    "  $$\n",
    "  \\text{score}(\\mathbf{u}, \\mathbf{v}) = \\mathbf{w}^\\top \\tanh(W_1\\mathbf{u} + W_2\\mathbf{v})\n",
    "  $$\n",
    "\n",
    "  Introduces three parameter sets $\\mathbf{w}$, $W_1$, and $W_2$.\n",
    "  Here, $\\mathbf{w} \\in \\mathbb{R}^d$ and $W_i \\in \\mathbb{R}^{d \\times d}$.\n",
    "\n",
    "  In total, $d + 2d^2$ parameters were introduced.\n",
    "\n",
    "- **Luong attention**\n",
    "\n",
    "  $$\n",
    "  \\text{score}(\\mathbf{u}, \\mathbf{v}) = \\mathbf{v}^\\top W \\mathbf{u}\n",
    "  $$\n",
    "\n",
    "  Introduces one parameter set $W$, where $W \\in \\mathbb{R}^{d \\times d}$.\n",
    "\n",
    "  In total, $d^2$ parameters were introduced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea2cb3",
   "metadata": {},
   "source": [
    "**Problem 1.3** (3 point) Using Bahdanau attention for the task of machine translation as an example, demonstrate how this attention mechanism captures long range dependencies. Support your answer with an example showing computation of attention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ad8707",
   "metadata": {},
   "source": [
    "Bahdanau attention allows the model to focus on different parts of the input sequence when producing each word of the output sequence.\n",
    "\n",
    "Let us consider a machine translation task. Let $\\mathbf{x}_i$ and $\\mathbf{y}_i$ be the $i$-th token of the source (input) and target (output) sequence. Also, denote by $\\mathbf{h}_i$ the hidden state of the encoder at time step $i$. Then, the context for decoding time step $i$ is given as a weighted sum of source tokens:\n",
    "\n",
    "$$\n",
    "\\mathbf{c}_i = \\sum_{j=1}^{|X|} \\alpha_{i, j} \\mathbf{h}_j\n",
    "$$\n",
    "\n",
    "Here, $\\alpha_{i, j}$ is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\alpha_{i, j} &= \\frac{\\exp(\\text{score}(\\mathbf{y}_{i-1}, \\mathbf{h}_j))}{\\sum_{k=1}^{|X|}\\exp(\\text{score}(\\mathbf{y}_{i-1}, \\mathbf{h}_k))}\\\\\n",
    "&= \\frac{\\exp(\\mathbf{w}^\\top \\tanh(W_1^\\top \\mathbf{y}_{i-1} + W_2^\\top \\mathbf{h}_j))}{\\sum_{k=1}^{|X|}\\exp(\\mathbf{w}^\\top \\tanh(W_1^\\top \\mathbf{y}_{i-1} + W_2^\\top \\mathbf{h}_k))}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $|X|$ is the number of tokens in the input sequence.\n",
    "\n",
    "Here, note that $\\mathbf{w} \\in \\mathbb{R}^d$ and $W_1, W_2 \\in \\mathbb{R}^{d \\times d}$ are all learnable parameters, as discussed in the previous problem.\n",
    "\n",
    "This captures long range dependencies by allowing the decoder to attend to all positions in the input sequence, regardless of their distance. When computing the attention weights, the model takes into consideration all encoder hidden states $\\mathbf{h}_j$â€‹ corresponding to each token in the source sequence, thus giving it the ability to learn which parts of the input are most relevant for producing the current output token.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cea9a1",
   "metadata": {},
   "source": [
    "**Problem 1.4** (1 point) In the context of dot-product attnetion, provide examples of scenarios where a particular attention weight $\\alpha_i$ dominates other attention weights in the distribution (i.e. $\\alpha_i \\gg \\alpha_j, \\forall j \\in \\{1, \\ldots, n\\}, i \\neq j$), and discuss the contexts or types of data where this could occur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513869a",
   "metadata": {},
   "source": [
    "In the context of dot-product attention, the attention weight $\\alpha_i$ is determined by the dot product of the query $\\mathbf{q}$ and key $\\mathbf{h}_i$â€‹. A larger dot product indicates a higher degree of similarity or alignment between the query and the key, leading to a larger attention weight after the softmax operation.\n",
    "\n",
    "In some cases, a particular attention weight might dominate other attention weights. One such possible scenario is that the source sequence containing redundant information. If the source sequence contains repeated or redundant information and the query strongly matches one of those repetitions, then that specific $\\alpha_i$â€‹ will dominate.\n",
    "\n",
    "Otherwise, if the query vector and one of the key vectors are almost parallel (or very similar in terms of direction and magnitude), their dot product will be high, causing that specific attention weight to dominate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eae788",
   "metadata": {},
   "source": [
    "**Problem 1.5** (2 points) Consider the role of multi-head attention in transformer models. How can it alleviate the problem of a single $\\alpha_i$ dominating the attention distribution? Provide examples to support your explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42214771",
   "metadata": {},
   "source": [
    "According to the paper 'Attention is All You Need', multi-head attention 'allows the model to jointly attend to information from different representation subspaces at different positions.' It is designed to capture different types of dependencies in the data by having multiple sets of attention weights and combining their outputs. This means that even if one attention head produces a dominating $\\alpha_i$â€‹, other heads might distribute attention differently, capturing other aspects of the input data.\n",
    "\n",
    "The multi-head attention is given as follows:\n",
    "\n",
    "$$\n",
    "\\text{MultiHead}(Q, K, V) = \\text{concat}(\\text{head}_1, \\cdots, \\text{head}_h)W^O\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{head}_i = \\text{Attention}(QW^Q_i, KW^K_i, VW^V_i),\\\\\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left( \\frac{QK^\\top}{\\sqrt{d_k}} \\right)V\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Here, different attention heads can potentially learn to focus on different parts of the input, thereby capturing diverse relationships in the data. For instance, one might focus on local dependencies, another on longer-range dependencies, and another on specific syntactic or semantic patterns.\n",
    "\n",
    "The followings are some examples.\n",
    "\n",
    "- **Anaphora Resolution**: In the sentence \"Jane dropped her pencil because she was in a hurry.\", the reference of \"she\" can be ambiguous without context. One attention head might focus predominantly on the word \"Jane\" to resolve the gender and identify the antecedent, while another head might attend more to the context \"in a hurry\" to capture the reason or action associated with \"Jane\". Together, they ensure that both the antecedent and the context are captured.\n",
    "\n",
    "- **Long-Range Dependencies**: In the sentence \"Despite the rain, the event, which many believed would be cancelled, went on as scheduled.\", capturing the relationship between \"rain\" and \"event\" can be crucial. While one head might attend strongly to \"rain\" when processing \"event\" to understand the potential challenge, another head might focus on \"went on as scheduled\" to capture the outcome. This ensures the model recognises both the potential issue (rain) and the resulting action (event not cancelled).\n",
    "\n",
    "- **Homonyms**: In the sentence \"The bank by the river had a lot of grass.\", understanding the correct meaning of \"bank\" is vital. One head might focus on \"river\" to capture the context that \"bank\" refers to the side of a river and not a financial institution, while another head might attend to \"grass\" to further support that interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be261c6d",
   "metadata": {},
   "source": [
    "# Problem 2 - Transformer Architecture (5 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2afe4d",
   "metadata": {},
   "source": [
    "**Problem 2.1** (2 points) In your own words, describe the key features of the transformer neural network architecture. Use equations where appropriate (max 200 words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03ea29",
   "metadata": {},
   "source": [
    "- **Self-Attention Mechanism**: At its core, transformers utilise self-attention, allowing each token in the input sequence to focus on other tokens, capturing dependencies irrespective of distance.\n",
    "\n",
    "- **Multi-Head Attention**: Rather than a single set of attention mechanisms, transformers deploy multiple heads working in parallel, each capturing different types of relationships or features in the data.\n",
    "\n",
    "- **Positional Encoding**: Since transformers lack inherent sequence awareness (unlike RNNs or LSTMs), they utilise positional encodings. These are added to the embeddings to provide information about the position of each token in the sequence.\n",
    "\n",
    "- **Feed-forward Neural Networks**: Each transformer block contains feed-forward neural networks operating on individual tokens independently, enabling parallel processing.\n",
    "\n",
    "- **Layer Normalisation & Residual Connections**: Each sub-layer (like self-attention or feed-forward neural networks) in a transformer has a residual connection around it, followed by layer normalisation. This helps in training deep transformer models by mitigating the vanishing gradient problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b96498",
   "metadata": {},
   "source": [
    "**Problem 2.2** (2 points) One of the features of the transformer architecture is the residual connections. The transformer architecture uses residual connections (https://arxiv.org/pdf/1512.03385.pdf) over both the feedforward and multi-head attention sub-layers.\n",
    "\n",
    "- (1) Describe how these residual connections function and the advantages of using them.\n",
    "- (2) Compare the derivative of the loss ($\\frac{\\partial L}{\\partial \\mathbf{x}}$) of a 2-layer feed-forward layer and a feed-forward layer with relu activation ($\\mathbf{z}= \\mathbf{W}_2^T \\text{ReLU}(\\mathbf{W}_1^T \\mathbf{x} + \\mathbf{b_1}) + \\mathbf{b_2}$) both with and without the residual connection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a4ebc",
   "metadata": {},
   "source": [
    "(1)\n",
    "\n",
    "Residual connections involve skipping one or more layers and directly adding the input to the output. There are some advantages to using the residual connections in the architecture. First, residual connections facilitate the backpropagation of gradients through the network, preventing the training signal from being unused in backpropagation step due to gradient vanishing. Thus, with residual connections, the network can be made deeper without the fear of making it harder to train, leading to better feature extraction and improved performance. Moreover, if some layers do not need to change the input representation, it is easier for them to learn the identity function with the help of residual connections.\n",
    "\n",
    "(2)\n",
    "\n",
    "We are given a 2-layer feed-forward layer with ReLU activation:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}= W_2^\\top \\text{ReLU}(W_1^\\top \\mathbf{x} + \\mathbf{b_1}) + \\mathbf{b_2}\n",
    "$$\n",
    "\n",
    "Without residual connection, if we want to compute $\\frac{\\partial L}{\\partial \\mathbf{x}}$, we would backpropagate through both the ReLU and the linear transformations:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}} &= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}}\\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{x}}\\\\\n",
    "&= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}} \\left( \\frac{\\partial}{\\partial \\mathbf{x}} \\left( W_2^\\top \\text{ReLU}(W_1^\\top \\mathbf{x} + \\mathbf{b_1}) + \\mathbf{b_2} \\right)\\right)\\\\\n",
    "&= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}} W_2^\\top W_1^\\top\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Since $\\frac{\\partial}{\\partial x} \\text{ReLU}(x)$ is either $1$ or $0$, for comparison let us assume that it has a derivative of $1$ for all indices of $W_1^\\top \\mathbf{x} + \\mathbf{b_1}$. i.e., $\\frac{\\partial}{\\partial \\mathbf{o}} \\text{ReLU}(\\mathbf{o}) = I$, where $\\mathbf{o} = W_1^\\top \\mathbf{x} + \\mathbf{b_1}$.\n",
    "\n",
    "With a residual connection, the output becomes:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = \\mathbf{x} + W_2^\\top \\text{ReLU}(W_1^\\top \\mathbf{x} + \\mathbf{b_1}) + \\mathbf{b_2}\n",
    "$$\n",
    "\n",
    "In this case, when computing $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}}$, there are two parts: the gradient flowing through the skipped connection and the gradient flowing through the layers:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}} &= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}}\\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{x}}\\\\\n",
    "&= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}} \\left( \\frac{\\partial}{\\partial \\mathbf{x}} \\left( \\mathbf{x} + W_2^\\top \\text{ReLU}(W_1^\\top \\mathbf{x} + \\mathbf{b_1}) + \\mathbf{b_2} \\right)\\right)\\\\\n",
    "&= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}} \\left( I + W_2^\\top W_1^\\top \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Again we assume that $\\frac{\\partial}{\\partial \\mathbf{o}} \\text{ReLU}(\\mathbf{o}) = I$. The dimensions of $I$ and $W_2^\\top W_1^\\top$ always match because by definition $\\mathbf{x}$ and $W_2^\\top \\text{ReLU}(\\mathbf{o})$ can be added together, thus having the same dimensions.\n",
    "\n",
    "The addition of $I$ is due to the residual connection. This ensures that a portion of the gradient always flows directly backward, which is the key reason residual connections help mitigate the vanishing gradient problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9240b7",
   "metadata": {},
   "source": [
    "**Problem 2.3** (1 point) What feature in the transformer architecture limits the ability of the transformer model to encode sequential information? Describe how positional encoding compensates for the model's lack of inherent sequence awareness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af724f04",
   "metadata": {},
   "source": [
    "Unlike RNNs and LSTMs, the transformer architecture doesn't inherently process sequences in a sequential manner. Instead, it processes all tokens in the input simultaneously. This parallel processing is one of the key reasons transformers are computationally efficient. However, this also means that in their base design, transformers lack inherent sequence awareness or the ability to naturally understand the order of tokens in a sequence.\n",
    "\n",
    "Positional encoding compensates for this limitation. Positional encoding provides a representation of position and injects this information into the model. By adding positional encodings to the embeddings of tokens before they are fed into the transformer, each token is provided with information about its position in the sequence.\n",
    "\n",
    "The most common positional encoding method is computed as following:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{PE}_{(\\text{pos}, 2i)} &= \\sin\\left( \\frac{\\text{pos}}{10000^{2i/d_m}} \\right)\\\\\n",
    "\\text{PE}_{(\\text{pos}, 2i+1)} &= \\cos\\left( \\frac{\\text{pos}}{10000^{2i/d_m}} \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $\\text{pos}$ is the position and $i$ is the dimension.\n",
    "\n",
    "The choice of this function is such that it provides a unique encoding for each position and is easily learnable. As the model trains, it can use these encodings to attend to tokens based on their position in the sequence, effectively giving the transformer a sense of order and allowing it to recognise patterns that depend on the position of tokens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9dae61",
   "metadata": {},
   "source": [
    "# Problem 3 - Transformer Language Model Training Objectives (10 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb685bc",
   "metadata": {},
   "source": [
    "This problem explores the T5 language model: https://arxiv.org/pdf/1910.10683.pdf\n",
    "The HuggingFace transformers implementation of T5 will be used. You will train the model from scratch. The pre-trained model must not be used. However, it is acceptable to use the built-in tokenizer without training it from scratch. Documentation for the HuggingFace implementation can be found here: https://huggingface.co/docs/transformers/model_doc/t5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713e037",
   "metadata": {},
   "source": [
    "**Problem 3.1** (2 points) Provide your own implementation of the training data generation function (Figure 2) for the unsupervised objective in T5. The input to your function should be original text from the internet. The two outputs of the function should be the masked text and the targets for the model to predict.\n",
    "\n",
    "- When implementing the function, randomly remove 15% of the tokens from the input text.\n",
    "- Demonstrate your function for a sample of 5 sentences.\n",
    "- The T5 tokenizer has special tokens for the placeholders: https://huggingface.co/t5-small/blob/main/tokenizer_config.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ab1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79209f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from transformers import T5Tokenizer\n",
    "from typing import List, Tuple\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "\n",
    "def mask_tokens(text: str) -> Tuple[List[str], List[str]]:\n",
    "    if not text:\n",
    "        return [\"\"], [\"\"]\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    token_len = len(tokens)\n",
    "    mask_count = int(0.15 * token_len)\n",
    "    if mask_count < 1:\n",
    "        return text, [\"\"]\n",
    "\n",
    "    mask_indices = random.sample(range(token_len), mask_count)\n",
    "    mask_indices.sort()\n",
    "\n",
    "    masked_input = []\n",
    "    targets = []\n",
    "    extra_id = 0\n",
    "    skip = False\n",
    "\n",
    "    for idx in range(token_len):\n",
    "        if skip:\n",
    "            skip = False\n",
    "            continue\n",
    "\n",
    "        if idx in mask_indices:\n",
    "            masked_input.append(f\"<extra_id_{extra_id}>\")\n",
    "            masked_span = [tokens[idx]]\n",
    "            while (idx + 1) in mask_indices:\n",
    "                idx += 1\n",
    "                masked_span.append(tokens[idx])\n",
    "                skip = True\n",
    "            if idx > 0:\n",
    "                targets.append(f\"<extra_id_{extra_id}>\")\n",
    "            targets.extend(masked_span)\n",
    "            extra_id += 1\n",
    "        else:\n",
    "            masked_input.append(tokens[idx])\n",
    "\n",
    "    if masked_input[-1] != f\"<extra_id_{extra_id - 1}>\":\n",
    "        targets.append(f\"<extra_id_{extra_id}>\")\n",
    "\n",
    "    return masked_input, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ffd84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: When an individual enters the presence of others, they commonly seek to acquire information about him or so to bring into play information about him already possessed.\n",
      "Input   : When an individual enters the presence <extra_id_0> <extra_id_1> they commonly seek to acquire information about him or so to bring into <extra_id_2> information about him already possessed.</s>\n",
      "Labels  : <extra_id_0> of others, <extra_id_1>, <extra_id_2> play <extra_id_3> </s>\n",
      "--------------------------------------------------\n",
      "Original: They will be interested in his general socio-economic status, his conception of self, his attitude towards them, his competence, his trustworthiness, etc.\n",
      "Input   : They will <extra_id_0> interested in his general <extra_id_1> -economic status, his conception of self, his <extra_id_2> towards them, his competence <extra_id_3> his trustworthiness, etc.</s>\n",
      "Labels  : <extra_id_0> be <extra_id_1> socio <extra_id_2> attitude <extra_id_3>, <extra_id_4> </s>\n",
      "--------------------------------------------------\n",
      "Original: Although some of this information seems to be sought almost as an end in itself, there are usually quite practical reasons for acquiring it.\n",
      "Input   : Although some <extra_id_0> this information seems <extra_id_1> be sought almost as an end in itself, there are usually quite <extra_id_2> reasons for <extra_id_3> acquiring it.</s>\n",
      "Labels  : <extra_id_0> of <extra_id_1> to <extra_id_2> practical <extra_id_3> <extra_id_4> </s>\n",
      "--------------------------------------------------\n",
      "Original: Information about the individual helps to define the situation, enabling others to know in advance what he will expect of them and what they may expect of him.\n",
      "Input   : Information about the individual helps <extra_id_0> define the situation, enabling others to know in advance <extra_id_1> he will expect of them and what <extra_id_2> may expect <extra_id_3> him.</s>\n",
      "Labels  : <extra_id_0> to <extra_id_1> what <extra_id_2> they <extra_id_3> of <extra_id_4> </s>\n",
      "--------------------------------------------------\n",
      "Original: Informed in these ways, the others will know how best to act in order to call forth a desired response from him.\n",
      "Input   : Informed in these ways <extra_id_0> the others <extra_id_1> know <extra_id_2> best to act in order to call forth a desired response from him.</s>\n",
      "Labels  : <extra_id_0>, <extra_id_1> will <extra_id_2> how <extra_id_3> </s>\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# From <The Presentation of Self in Everyday Life> by Erving Goffman :)\n",
    "sentences = [\n",
    "    \"When an individual enters the presence of others, they commonly seek to acquire information about him or so to bring into play information about him already possessed.\",\n",
    "    \"They will be interested in his general socio-economic status, his conception of self, his attitude towards them, his competence, his trustworthiness, etc.\",\n",
    "    \"Although some of this information seems to be sought almost as an end in itself, there are usually quite practical reasons for acquiring it.\",\n",
    "    \"Information about the individual helps to define the situation, enabling others to know in advance what he will expect of them and what they may expect of him.\",\n",
    "    \"Informed in these ways, the others will know how best to act in order to call forth a desired response from him.\",\n",
    "]\n",
    "\n",
    "\n",
    "for sentence in sentences:\n",
    "    input_text, labels = mask_tokens(sentence)\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Original:\", sentence)\n",
    "    print(\"Input   :\", tokenizer.decode(tokenizer.encode(input_text)))\n",
    "    print(\"Labels  :\", tokenizer.decode(tokenizer.encode(labels)))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a9fcc",
   "metadata": {},
   "source": [
    "**Problem 3.2** (2 points) After T5 model is pre-trained with the unsupervised objective, (Raffel et al. 2019) fine-tuned for a number of downstream natural language understanding tasks. What is meant by pre-training and fine-tuning? Provide references to other notable examples / models in recent NLP papers other than T5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a7bac",
   "metadata": {},
   "source": [
    "- **Pre-training**: In the context of neural networks and particularly in NLP models, pre-training refers to training a model on a large dataset, often with vast amounts of text, to learn underlying patterns, structures, and representations in the language. This process typically involves a general objective, like predicting the next word in a sequence (language modelling), which allows the model to gain a broad understanding of the language. The resulting model can capture a lot of the syntax, semantics, and even some of the world knowledge embedded in the training data.\n",
    "\n",
    "- **Fine-tuning**: After the pre-training phase, the model, which has now learned general language features, is further trained on a smaller, task-specific dataset. This process is called fine-tuning. During fine-tuning, the model is tailored to perform a specific task, such as classification, translation, question-answering, etc., and adapts its previously learned general knowledge to this specific task.\n",
    "\n",
    "Notable examples/models in recent NLP research that use pre-training and fine-tuning include:\n",
    "\n",
    "- **GPT**: GPT is pre-trained as a unidirectional language model, and fine-tuned for specific tasks. It is trained to predict the next token given some context window.\\\n",
    "  _Reference: [Improving Language Understanding by Generative Pre-training](https://www.mikecaptain.com/resources/pdf/GPT-1.pdf)_\n",
    "\n",
    "- **LLaMA**: LLaMA has a similar architecture to GPT, and is pre-trained on publicly available datasets (such as English CommonCrawl, Github, and Wikipedia) exclusively.\\\n",
    "  _Reference: [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)_\n",
    "\n",
    "- **ChatDoctor**: ChatDoctor is a specialised language model with enhanced accuracy in medical advice, created by fine-tuning the pretrained LLaMA model using a large dataset of 100,000 patient-doctor dialogues sourced from a widely used online medical consultation platform.\\\n",
    "  _Reference: [ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge](https://arxiv.org/abs/2303.14070)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942cbeb",
   "metadata": {},
   "source": [
    "**Problem 3.3** (2 points) Transformer models, such as T5, are often trained with learning rate schedule such as inverse square root: where $s = 1/\\sqrt{\\max(n,k)}$ where n is the number of warm up steps and k is the current step number.\n",
    "\n",
    "- Provde a python implementation of this learning rate schedule function\n",
    "- For n=10000, plot the schedule $s$ against $k$.\n",
    "- Explain in your own words why this learning rate schedule could benefit training a transformer model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00263779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def inverse_sqrt_lr(k: int, n: int = 10000) -> float:\n",
    "    if k == 0:\n",
    "        return 1 / np.sqrt(n)\n",
    "    return 1 / np.sqrt(max(n, k))\n",
    "\n",
    "\n",
    "k_values = np.arange(1, 50000)\n",
    "s_values = [inverse_sqrt_lr(k, n=10000) for k in k_values]\n",
    "\n",
    "plt.plot(k_values, s_values)\n",
    "plt.title(\"Learning Rate vs. Step\")\n",
    "plt.xlabel(\"Step (k)\")\n",
    "plt.ylabel(\"Learning Rate (s)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8691e78",
   "metadata": {},
   "source": [
    "This schedule benefits the training of transformer models in several ways.\n",
    "\n",
    "At the beginning of training, when weights are initialised (often randomly), the model's predictions are likely far from optimal. Thus, a higher learning rate allows the model to make larger updates and converge faster.\n",
    "\n",
    "As training progresses, the model starts to fit the data more closely, and the loss landscape becomes more intricate with narrower regions of interest. Here, using a high learning rate might make the model overshoot these narrow regions. Hence, reducing the learning rate as training goes on allows the model to make finer adjustments and potentially settle into deeper, narrower parts of the loss function (i.e., local minima).\n",
    "\n",
    "If the learning rate was constant, with high learning rates, the model might bounce around and miss the local minima, while extremely low learning rates might make the model converge too slowly or get stuck in less optimal minima. The inverse square root schedule tries to get the best of both worlds by starting fast and then slowing down, allowing the model to navigate the complex loss landscape of Transformer models effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e86964",
   "metadata": {},
   "source": [
    "**Problem 3.4** (4 points) Using the huggingface library, initialize a new instance of a T5-small model (i.e. randomly initialized, do not use the pre-trained model) and train it on WikiText103 dataset with the T5 unsupervised pretraining objective.\n",
    "\n",
    "- Report your training and validation loss. Submit a graph of these along with your submission of the jupyter notebook.\n",
    "- Budget a maximum of 2 hours of training time\n",
    "- It is recommended to use the learning rate and scheduling hyperparemeters reported in the paper. However, smaller batch sizes and smaller max sequence lenghts are recommended for for slower hardware.\n",
    "- PyTorch does not have the correct learning rate scheduler, a suitable alternative would be LamdaLR function and to call the function you wrote in Problem 3.3. https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LambdaLR.html\n",
    "- It is acceptable to use the HuggingFace tokenizer, you do not have to train this from scratch.\n",
    "- It is acceptable to use the HuggingFace trainer\n",
    "- Graphing the training/validation loss may be achieved using W&B, TensorBoard or similar, or implemented manually\n",
    "\n",
    "(Rubric: 1 point pre-processing and packing data, 1 point for appropriate training, 2 points successful convergence on the training/validation loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be0fc1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e4b6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
    "\n",
    "\n",
    "class MaskedDataset(Dataset):\n",
    "    def __init__(self, data: datasets.Dataset):\n",
    "        self.data = data\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "        self.max_token_len = 128\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        text = self.data[idx][\"text\"]\n",
    "        masked_input, labels = mask_tokens(text)\n",
    "        masked_input = self.tokenizer.encode(\n",
    "            masked_input,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_tensors=\"pt\",\n",
    "        ).squeeze()\n",
    "        labels = self.tokenizer.encode(\n",
    "            labels,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_tensors=\"pt\",\n",
    "        ).squeeze()\n",
    "        # labels[labels == self.tokenizer.pad_token_id] = -100  # ignore loss\n",
    "\n",
    "        return {\"input_ids\": masked_input, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21d96e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MaskedDataset(data[\"train\"])\n",
    "val_dataset = MaskedDataset(data[\"validation\"])\n",
    "test_dataset = MaskedDataset(data[\"test\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ccb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import wandb\n",
    "from transformers import T5Config, T5ForConditionalGeneration\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "config = T5Config(\n",
    "    vocab_size=tokenizer.vocab_size + 128,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    decoder_start_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "model = T5ForConditionalGeneration(config)  # Randomly initialised\n",
    "model = model.to(device)\n",
    "optimizer = transformers.Adafactor(model.parameters(), lr=1, relative_step=False)\n",
    "scheduler = LambdaLR(optimizer, lambda k: inverse_sqrt_lr(k, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09250f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"ai605-assignment2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d471392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1125845 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial learning rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1125845 [00:00<289:28:07,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 0, Training Loss: 6.0109, Learning Rate: 0.01\n",
      "Epoch 1/5, Iteration 0, Validation Loss: 2.4071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 101/1125845 [03:22<244:13:29,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 100, Training Loss: 0.1421, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 201/1125845 [04:42<238:29:48,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 200, Training Loss: 0.4408, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 301/1125845 [06:01<249:45:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 300, Training Loss: 0.8624, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 401/1125845 [07:21<254:10:45,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 400, Training Loss: 0.9106, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 501/1125845 [08:39<247:06:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 500, Training Loss: 0.8955, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 601/1125845 [09:58<247:35:50,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 600, Training Loss: 0.5135, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 701/1125845 [11:17<254:30:40,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 700, Training Loss: 0.3136, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 801/1125845 [12:36<239:29:07,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 800, Training Loss: 1.1899, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 901/1125845 [13:55<246:34:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 900, Training Loss: 0.9626, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1001/1125845 [15:13<243:39:55,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 1000, Training Loss: 0.3763, Learning Rate: 0.01\n",
      "Epoch 1/5, Iteration 1000, Validation Loss: 0.6829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1101/1125845 [18:35<255:28:35,  1.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 1100, Training Loss: 0.3519, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1201/1125845 [19:53<246:22:34,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 1200, Training Loss: 0.6748, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1301/1125845 [21:14<255:05:40,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 1300, Training Loss: 0.8342, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1401/1125845 [22:35<255:25:11,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 1400, Training Loss: 0.9427, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1501/1125845 [23:55<255:34:48,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 1500, Training Loss: 0.9872, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1601/1125845 [25:15<253:02:02,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 1600, Training Loss: 0.5856, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1701/1125845 [26:35<251:34:40,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 1700, Training Loss: 0.5601, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1801/1125845 [27:56<257:59:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 1800, Training Loss: 0.5107, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1901/1125845 [29:16<252:09:33,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 1900, Training Loss: 1.1019, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2001/1125845 [30:38<256:11:19,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 2000, Training Loss: 0.9080, Learning Rate: 0.01\n",
      "Epoch 1/5, Iteration 2000, Validation Loss: 0.6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2101/1125845 [34:02<263:15:46,  1.19it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 2100, Training Loss: 0.8763, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2201/1125845 [35:24<257:43:53,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 2200, Training Loss: 0.1151, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2301/1125845 [36:45<244:23:20,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 2300, Training Loss: 0.4655, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2401/1125845 [38:05<243:42:21,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 2400, Training Loss: 0.9863, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2501/1125845 [39:26<252:10:14,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 2500, Training Loss: 0.5787, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2601/1125845 [40:46<257:15:19,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 2600, Training Loss: 0.7824, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2701/1125845 [42:07<250:57:18,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 2700, Training Loss: 0.4050, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2801/1125845 [43:30<256:40:28,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 2800, Training Loss: 0.6250, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2901/1125845 [44:53<268:10:46,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 2900, Training Loss: 0.6668, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3001/1125845 [46:18<268:14:39,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 3000, Training Loss: 0.8066, Learning Rate: 0.01\n",
      "Epoch 1/5, Iteration 3000, Validation Loss: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3101/1125845 [49:48<264:24:37,  1.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 3100, Training Loss: 0.8791, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3201/1125845 [51:13<276:46:06,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 3200, Training Loss: 0.2673, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3301/1125845 [52:40<285:26:27,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 3300, Training Loss: 1.0754, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3401/1125845 [54:09<279:37:01,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 3400, Training Loss: 0.4489, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3501/1125845 [55:38<283:47:17,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 3500, Training Loss: 1.3801, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3601/1125845 [57:05<259:02:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 3600, Training Loss: 0.4127, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3701/1125845 [58:30<275:06:08,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 3700, Training Loss: 0.4326, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3801/1125845 [59:57<257:19:28,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 3800, Training Loss: 0.8498, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3901/1125845 [1:01:25<279:32:12,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 3900, Training Loss: 0.3520, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4001/1125845 [1:02:56<275:14:58,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 4000, Training Loss: 0.7633, Learning Rate: 0.01\n",
      "Epoch 1/5, Iteration 4000, Validation Loss: 0.6496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4101/1125845 [1:06:30<286:17:59,  1.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 4100, Training Loss: 0.3971, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4201/1125845 [1:08:02<285:27:53,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 4200, Training Loss: 0.2348, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4301/1125845 [1:09:35<280:39:50,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 4300, Training Loss: 0.1904, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4401/1125845 [1:11:08<282:58:12,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 4400, Training Loss: 0.1532, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4501/1125845 [1:12:41<293:53:57,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 4500, Training Loss: 0.8515, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4601/1125845 [1:14:14<288:11:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 4600, Training Loss: 0.6148, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4701/1125845 [1:15:44<269:08:49,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 4700, Training Loss: 0.0022, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4801/1125845 [1:17:17<276:53:37,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 4800, Training Loss: 0.5441, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4901/1125845 [1:18:48<279:20:05,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 4900, Training Loss: 0.4396, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5001/1125845 [1:20:22<274:11:23,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 5000, Training Loss: 0.0019, Learning Rate: 0.01\n",
      "Epoch 1/5, Iteration 5000, Validation Loss: 0.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5101/1125845 [1:23:55<283:39:47,  1.10it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 5100, Training Loss: 0.3274, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5201/1125845 [1:25:26<287:12:15,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 5200, Training Loss: 0.2755, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5301/1125845 [1:26:56<273:57:32,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 5300, Training Loss: 0.4958, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5401/1125845 [1:28:24<282:43:53,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 5400, Training Loss: 0.1939, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5501/1125845 [1:29:54<278:17:48,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 5500, Training Loss: 0.9105, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5601/1125845 [1:31:23<294:15:36,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 5600, Training Loss: 1.4044, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5701/1125845 [1:32:53<277:29:11,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 5700, Training Loss: 0.4694, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5801/1125845 [1:34:23<285:51:44,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 5800, Training Loss: 0.4394, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5901/1125845 [1:35:52<285:15:04,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 5900, Training Loss: 0.6268, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6001/1125845 [1:37:24<288:17:16,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 6000, Training Loss: 1.3688, Learning Rate: 0.01\n",
      "Epoch 1/5, Iteration 6000, Validation Loss: 0.6418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6101/1125845 [1:40:59<289:27:38,  1.07it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 6100, Training Loss: 1.0883, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6201/1125845 [1:42:30<273:02:50,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 6200, Training Loss: 0.4542, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6301/1125845 [1:44:02<282:04:37,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 6300, Training Loss: 0.8508, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6401/1125845 [1:45:35<290:33:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 6400, Training Loss: 0.5461, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6501/1125845 [1:47:07<298:44:07,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 6500, Training Loss: 0.7250, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6601/1125845 [1:48:42<286:20:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 6600, Training Loss: 0.4029, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6701/1125845 [1:50:15<290:23:59,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 6700, Training Loss: 1.0355, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6801/1125845 [1:51:50<277:54:35,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 6800, Training Loss: 0.3473, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6901/1125845 [1:53:25<294:00:36,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 6900, Training Loss: 0.4436, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7001/1125845 [1:55:00<316:54:42,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 7000, Training Loss: 0.6910, Learning Rate: 0.01\n",
      "Epoch 1/5, Iteration 7000, Validation Loss: 0.6431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7101/1125845 [1:58:42<307:51:39,  1.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 7100, Training Loss: 0.5539, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7201/1125845 [2:00:17<295:42:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 7200, Training Loss: 0.7085, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7301/1125845 [2:01:54<289:48:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 7300, Training Loss: 0.1984, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7401/1125845 [2:03:32<303:17:55,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 7400, Training Loss: 0.1512, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7501/1125845 [2:05:12<307:19:26,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 7500, Training Loss: 0.3348, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7601/1125845 [2:06:53<324:22:20,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 7600, Training Loss: 0.8087, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7701/1125845 [2:08:33<316:32:42,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 7700, Training Loss: 0.2775, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7801/1125845 [2:10:13<308:46:21,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 7800, Training Loss: 0.7362, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7901/1125845 [2:11:53<310:17:11,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 7900, Training Loss: 0.5587, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8001/1125845 [2:13:32<295:33:18,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 8000, Training Loss: 0.1535, Learning Rate: 0.01\n",
      "Epoch 1/5, Iteration 8000, Validation Loss: 0.6452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8101/1125845 [2:17:17<306:04:43,  1.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 8100, Training Loss: 0.6685, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8201/1125845 [2:18:58<312:01:34,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 8200, Training Loss: 1.2352, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8301/1125845 [2:20:35<285:08:59,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 8300, Training Loss: 0.3700, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8401/1125845 [2:22:12<300:11:17,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 8400, Training Loss: 0.3516, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8501/1125845 [2:23:48<299:44:20,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 8500, Training Loss: 0.8078, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8601/1125845 [2:25:27<306:20:54,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 8600, Training Loss: 0.4425, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8701/1125845 [2:27:07<312:25:30,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 8700, Training Loss: 0.9068, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8801/1125845 [2:28:49<318:20:21,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 8800, Training Loss: 0.8079, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8901/1125845 [2:30:31<306:50:25,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 8900, Training Loss: 0.1326, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9001/1125845 [2:32:14<309:29:57,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 9000, Training Loss: 0.4548, Learning Rate: 0.01\n",
      "Epoch 1/5, Iteration 9000, Validation Loss: 0.6378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9101/1125845 [2:36:08<339:15:11,  1.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 9100, Training Loss: 0.9248, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9201/1125845 [2:37:52<326:25:23,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 9200, Training Loss: 0.8560, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9301/1125845 [2:39:38<332:29:02,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 9300, Training Loss: 0.6999, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9401/1125845 [2:41:25<330:41:12,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 9400, Training Loss: 0.3389, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9501/1125845 [2:43:12<333:53:22,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 9500, Training Loss: 0.4878, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9601/1125845 [2:44:59<329:10:19,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 9600, Training Loss: 0.4207, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9701/1125845 [2:46:46<329:41:07,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 9700, Training Loss: 0.3955, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9801/1125845 [2:48:33<331:14:03,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 9800, Training Loss: 0.7812, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9901/1125845 [2:50:19<328:06:42,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 9900, Training Loss: 0.2062, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10001/1125845 [2:52:05<318:11:57,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 10000, Training Loss: 0.4908, Learning Rate: 0.009999500037496875\n",
      "Epoch 1/5, Iteration 10000, Validation Loss: 0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10101/1125845 [2:55:59<332:23:43,  1.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 10100, Training Loss: 0.3145, Learning Rate: 0.009949879346007117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10201/1125845 [2:57:47<354:19:28,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 10200, Training Loss: 0.6328, Learning Rate: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10301/1125845 [2:59:39<367:02:30,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 10300, Training Loss: 1.4924, Learning Rate: 0.009852814501285315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10401/1125845 [3:01:35<363:11:07,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 10400, Training Loss: 0.5835, Learning Rate: 0.009805335357886892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10501/1125845 [3:03:25<338:06:05,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 10500, Training Loss: 0.5722, Learning Rate: 0.009758536048356126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10601/1125845 [3:05:09<311:55:33,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 10600, Training Loss: 0.4313, Learning Rate: 0.00971240050227797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10701/1125845 [3:06:55<326:47:05,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 10700, Training Loss: 0.2701, Learning Rate: 0.009666913176095693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10801/1125845 [3:08:44<361:05:39,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 10800, Training Loss: 0.1873, Learning Rate: 0.009622059031109105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10901/1125845 [3:10:36<329:17:41,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 10900, Training Loss: 0.8968, Learning Rate: 0.009577823512585466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11001/1125845 [3:12:25<317:17:18,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 11000, Training Loss: 0.9872, Learning Rate: 0.009534192529917124\n",
      "Epoch 1/5, Iteration 11000, Validation Loss: 0.6354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11101/1125845 [3:16:25<346:29:16,  1.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 11100, Training Loss: 0.6580, Learning Rate: 0.009491152437764508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11201/1125845 [3:18:15<339:25:16,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 11200, Training Loss: 0.8448, Learning Rate: 0.009448690018127141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11301/1125845 [3:20:00<305:36:49,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Iteration 11300, Training Loss: 0.7788, Learning Rate: 0.009406792463289175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11361/1125845 [3:21:01<310:53:59,  1.00s/it]"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "progress_bar = tqdm(range(num_epochs * len(train_loader)))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Initial learning rate: {}\".format(optimizer.state_dict()[\"param_groups\"][0][\"lr\"])\n",
    ")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for train_iter, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        wandb.log({\"Training Loss\": loss.item()})\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update()\n",
    "\n",
    "        if train_iter % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{num_epochs}, Iteration {train_iter}, Training Loss: {loss.item():.4f}, Learning Rate: {optimizer.state_dict()['param_groups'][0]['lr']}\"\n",
    "            )\n",
    "        if train_iter % 1000 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0\n",
    "                for _, batch in enumerate(val_loader):\n",
    "                    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                    outputs = model(**batch)\n",
    "                    val_loss += outputs.loss\n",
    "\n",
    "                val_loss /= len(val_loader)\n",
    "\n",
    "                wandb.log({\"Validation Loss\": val_loss})\n",
    "                print(\n",
    "                    f\"Epoch {epoch + 1}/{num_epochs}, Iteration {train_iter}, Validation Loss: {val_loss:.4f}\"\n",
    "                )\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": loss,\n",
    "        },\n",
    "        f\"./t5_from_scratch.pth\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
